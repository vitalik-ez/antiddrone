<html>
<head>
    <!--<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.12.0/dist/tf.min.js"></script>-->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"> </script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.12.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet@latest"></script>

    <!--
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-cpu"></script>
    Import @tensorflow/tfjs-tflite
    Note that we need to explicitly load dist/tf-tflite.min.js so that it can
    locate WASM module files from their default location (dist/).
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-tflite/dist/tf-tflite.min.js"></script>-->
</head>
<body>

    <div>
        <p>change</p>
        <video id="video" autoplay muted playsinline></video>
        <canvas id="canvas" width="800" height="400"></canvas>
    </div>

    <div id="status"></div>

    

    <script>
        async function loadModel() {
            return tf.loadGraphModel("content/yolov5n_web_model/model.json");
        }

        /*
        async function doPredict() {
            const tfliteModel = tflite.loadTFLiteModel(
                'https://tfhub.dev/tensorflow/lite-model/mobilenet_v2_1.0_224/1/metadata/1');

            const outputTensor = tf.tidy(() => {
                // Get pixels data from an image.
                const img = tf.browser.fromPixels(document.getElementById('image'));
                // Normalize (might also do resize here if necessary).
                const input = tf.sub(tf.div(tf.expandDims(img), 127.5), 1);
                // Run the inference.
                let outputTensor = tfliteModel.predict(input); //  as tf.Tensor
                // De-normalize the result.
                return tf.mul(tf.add(outputTensor, 1), 127.5)
            });
            console.log("outputTensor");
            console.log(outputTensor);
        }

        function preprocess(imageData) {
            let imageTensor = tf.browser.fromPixels(imageData, numChannels=3);
            const resized = tf.image.resizeBilinear(imageTensor, [640, 640]).toFloat()
            const offset = tf.scalar(255.0);
            const normalized = tf.scalar(1.0).sub(resized.div(offset));
            const batched = normalized.expandDims(0);
            return batched;
        }*/

        
        (async () => {

            const model = await loadModel();
            console.log("Model was loaded");

            //const model = await mobilenet.load();
            
            const status = document.getElementById('status');
            const video = document.getElementById('video');
            const canvas = document.getElementById('canvas');
            const context = canvas.getContext('2d');


            const stream = await navigator.mediaDevices.getUserMedia({
                audio: false,
                video: {
                    facingMode: 'environment'
                }
            })

            video.srcObject = stream

            predict()

            async function predict() {
                context.drawImage(video, 0, 0, 500, 500)
                //const predictions = await model.classify(canvas);
                let output = await model.executeAsync(canvas);
                
                console.log("output", output);
                /*
                const boxes = output[0].dataSync();
                const scores = output[1].arraySync();
                const classes = output[2].dataSync();

                console.log("boxes", boxes);
                console.log("scores", scores);
                console.log("classes", classes);
                status.innerHTML = `classes ${classes}`*/
                requestAnimationFrame(predict)
            }
        })()

    </script>

    
</body>

</html>